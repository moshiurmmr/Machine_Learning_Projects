<< This project is a work in progress .....
Note: - when using different models in Spyder IDE, restart the kernel after running each model. This will reset the variables in
kernel, otherwise subsequent models will show errors while running.
- if Jupyter notebook is used for running the models, make sure to reset the notebook before running each model.
>>

This project builds machine learning models for the very well known Titanic dataset, Titanic: Machine Learning from Disaster 
(https://www.kaggle.com/c/titanic).

The goal of the model is to predict the survival probability of the passengers given their name, sex, age, ticket, fare, cabin,
place ofembarkment, passenger class, etc.

1. The data is available in the 'titanic_data' folder

2. Data preprocessing: a number of data preprocessing operation have been carried out to select the more relevant features for 
the modeling purpose and to 'polish' data for missing values and categorical values. 
    i. data having unique features is removed using the function, 'removeUniqueFeature.py'. The reason is, if the the data is
    unique for all the training samples for a particular feature, there is no useful correlation information for the feature,
    hence, the entropy is null. This type of data is not useful, so they are removed.  
    ii. The features that has missing values is imputed using the 'imputeWithAvgValue.py' function. 
    iii. The categorical features are one hot encoded using the function, 'oneHotEncode.py'.
    
3. A number of classical machine learning models (i.e., Logistic regression, Decission Tree, Random Forest classifier ) have 
been developed in the 'Titanic_ML_from_disaster_classical_models.py' file.

4. A neural network model using Keras is developed in 'Titanic_ML_from_disaster_NN_Keras_model.py'.

5. A neural network model using Tensorflow is developed in 'Titanic_ML_from_disaster_NN_TF_model.py'.
